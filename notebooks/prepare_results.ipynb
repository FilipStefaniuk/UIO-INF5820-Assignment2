{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Basic operations with word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have selected two words: *current* and *classify* and created tables with similar words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../results/similar_words/3.json') as f:\n",
    "    similar_3 = json.load(f)\n",
    "\n",
    "with open('../results/similar_words/29.json') as f:\n",
    "    similar_29 = json.load(f)\n",
    "\n",
    "def similarities_table(index_nr, filename):\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'Wikipedia' :similar_3[index_nr]['similar_words'],\n",
    "        'Wikipedia scores': similar_3[index_nr]['similar_scores'],\n",
    "        'Gigaword': similar_29[index_nr]['similar_words'],\n",
    "        'Gigaword scores': similar_29[index_nr]['similar_scores']\n",
    "    }, index=similar_3[index_nr]['similar_idx'])\n",
    "\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(df.to_latex())\n",
    "    \n",
    "similarities_table(1, '../report/similarities_current.tex')\n",
    "similarities_table(4, '../report/similarities_classify.tex')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Intrinsic evaluation of pre-trained word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../results/intrinsic_eval/40.json') as f:\n",
    "    intrinsic_40 = json.load(f)\n",
    "with open('../results/intrinsic_eval/75.json') as f:\n",
    "    intrinsic_75 = json.load(f)\n",
    "with open('../results/intrinsic_eval/82.json') as f:\n",
    "    intrinsic_82 = json.load(f)\n",
    "    \n",
    "models = [('40 CoNLL-17', intrinsic_40), ('75 Oil and Gas', intrinsic_75), ('82 Common Crawl', intrinsic_82)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results from evaluation on Simlex:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simlex_table(models, filename, filename2):\n",
    "    sections = ['adj', 'noun', 'verb', 'total']\n",
    "    \n",
    "    simlex_oov = {}\n",
    "    simlex_results = {}\n",
    "    for name, model in models:\n",
    "        simlex_results[name] = [model['simlex'][x]['pearson'][0] for x in sections]\n",
    "        simlex_oov[name] = [model['simlex'][x]['oov_ratio'] for x in sections]\n",
    "\n",
    "    df = pd.DataFrame(simlex_results, index=sections)\n",
    "    df2 = pd.DataFrame(simlex_oov, index=sections)\n",
    "    \n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(df.to_latex())\n",
    "\n",
    "    with open(filename2, \"w\") as f:\n",
    "        f.write(df2.to_latex())\n",
    "        \n",
    "simlex_table(models, '../report/simlex_table_1.tex', '../report/simlex_oov_table_1.tex')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results from evaluation on Google Analogies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analogies_table(models, filename):\n",
    "#     sections = sorted(intrinsic_40['analogies'].keys(), reverse=True)\n",
    "\n",
    "    analogies_results = {}\n",
    "    for name, model in models:\n",
    "        sections = model['analogies']['sections']\n",
    "        analogies_results[name] = [model['analogies']['scores'].get(x, None) for x in sections]\n",
    "\n",
    "        \n",
    "    df = pd.DataFrame(analogies_results, index=sections)\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(df.to_latex())\n",
    "        \n",
    "analogies_table(models, '../report/analogies_table_1.tex')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Training a word embedding model on in-domain data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "paste -d \"\\t\" \\\n",
    "<(zcat ../vectors/signal_1.txt.gz | tail -n +2 | head -n 20 | cut -f1 -d ' ') \\\n",
    "<(unzip -c ../../vectors/40.zip model.txt | tail -n +4 | head -n 20 | cut -f1 -d ' ') \\\n",
    "<(unzip -c ../../vectors/75.zip model.txt | tail -n +4 | head -n 20 | cut -f1 -d ' ') \\\n",
    "<(unzip -c ../../vectors/82.zip model.txt | tail -n +4 | head -n 20 | cut -f1 -d ' ') \\\n",
    ">../results/top_words.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.genfromtxt('../results/top_words.csv', delimiter='\\t', dtype=np.str),\n",
    "             columns=['SignalMedia', 'CoNLL17', 'Oil and Gas', 'Common Crawl'])\n",
    "\n",
    "with open('../report/top_words.tex', \"w\") as f:\n",
    "    f.write(df.head(10).to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../results/intrinsic_eval/signal_1.json') as f:\n",
    "    intrinsic_signal_1 = json.load(f)\n",
    "with open('../results/intrinsic_eval/signal_2.json') as f:\n",
    "    intrinsic_signal_2 = json.load(f)\n",
    "models_2 = [('SignalMedia1', intrinsic_signal_1), ('SignalMedia2', intrinsic_signal_2)]\n",
    "simlex_table(models_2, '../report/simlex_table_2.tex', '../report/simlex_oov_table_2.tex')\n",
    "analogies_table(models_2, '../report/analogies_table_2.tex')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4: Document classification with word embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = sorted(os.listdir('../results/classifier'))\n",
    "\n",
    "results = {}\n",
    "for experiment in dirs:\n",
    "    with open(os.path.join('../results/classifier', experiment, 'metrics.json')) as f:\n",
    "        x = json.load(f)\n",
    "        f1 = np.round(x['f1'], 3).tolist()\n",
    "        f1.append(np.round(x['avg_f1'], 3))\n",
    "        labels = x['labels']\n",
    "        labels.append('Average')\n",
    "        results[experiment] = f1\n",
    "\n",
    "results = pd.DataFrame(results, index=labels)\n",
    "\n",
    "with open('../report/classification_results.tex', \"w\") as f:\n",
    "    f.write(results.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_dirs = sorted(os.listdir('../results/best'))\n",
    "\n",
    "\n",
    "precision = []\n",
    "recall = []\n",
    "f1 = []\n",
    "\n",
    "\n",
    "for exp in best_dirs:\n",
    "    with open(os.path.join('../results/best', exp, 'metrics.json'), \"r\") as f:\n",
    "        x = json.load(f) \n",
    "        precision.append(x['precision'] + [x['avg_precision']])\n",
    "        recall.append(x['recall'] + [x['avg_recall']])\n",
    "        f1.append(x['f1'] + [x['avg_f1']])\n",
    "        labels = x['labels']\n",
    "        labels.append('Average')\n",
    "\n",
    "        \n",
    "avg_precision = np.mean(precision, axis=0)\n",
    "avg_recall = np.mean(recall, axis=0)\n",
    "avg_f1 = np.mean(f1, axis=0)\n",
    "\n",
    "std_precision = np.std(precision, axis=0)\n",
    "std_recall = np.std(recall, axis=0)\n",
    "std_f1 = np.std(f1, axis=0)\n",
    "\n",
    "avg_df = pd.DataFrame({'precision':avg_precision, 'recall':avg_recall, 'f1':avg_f1}, index=labels)\n",
    "std_df = pd.DataFrame({'precision':std_precision, 'recall':std_recall, 'f1':std_f1}, index=labels)\n",
    "\n",
    "with open('../report/best_avg.tex', \"w\") as f:\n",
    "    f.write(avg_df.to_latex())\n",
    "    \n",
    "with open('../report/best_std.tex', \"w\") as f:\n",
    "    f.write(std_df.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:inf5820]",
   "language": "python",
   "name": "conda-env-inf5820-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
